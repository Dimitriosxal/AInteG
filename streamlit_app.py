import os
import re
import json
from pathlib import Path

import requests
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv

# =====================================================
# LOAD .env (bulletproof)
# =====================================================
BASE_DIR = Path(__file__).resolve().parent
ENV_PATH = BASE_DIR / ".env"
load_dotenv(ENV_PATH)

API_URL = "http://127.0.0.1:8001"

# =====================================================
# Streamlit basic config
# =====================================================
st.set_page_config(page_title="AInteG Console", layout="centered")
st.title("AInteG Management Console")
st.markdown("### Î”Î¹Î¬Î»ÎµÎ¾Îµ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î± (General Î® Invoice)")

# Î¦Î¬ÎºÎµÎ»Î¿Î¹ uploads (Î³Î¹Î± file manager)
GENERAL_UPLOAD_DIR = Path("uploads/general")
INVOICE_UPLOAD_DIR = Path("uploads/invoices")
GENERAL_UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
INVOICE_UPLOAD_DIR.mkdir(parents=True, exist_ok=True)


# =====================================================
# OpenAI client helper
# =====================================================
def get_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        # Î”ÎµÎ½ ÏÎ¯Ï‡Î½Î¿Ï…Î¼Îµ exception â€” ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ None ÎºÎ±Î¹ Î´Î¯Î½Î¿Ï…Î¼Îµ Î¼Î®Î½Ï…Î¼Î± ÏƒÏ„Î¿ UI
        return None
    return OpenAI(api_key=api_key)


# =====================================================
# Helpers
# =====================================================
def highlight_snippet(text: str, query: str, max_len: int = 400) -> str:
    """ÎœÎ¹ÎºÏÏŒ snippet Î³ÏÏÏ‰ Î±Ï€ÏŒ Ï„Î¿ query, Î¼Îµ bold ÏƒÏ„Î¿ query."""
    if not text:
        return ""

    idx = text.lower().find(query.lower())
    if idx != -1:
        start = max(0, idx - 120)
        end = min(len(text), idx + 120)
        snippet = text[start:end]
    else:
        snippet = text[:max_len]

    pattern = re.compile(re.escape(query), re.IGNORECASE)
    snippet = pattern.sub(lambda m: f"**{m.group(0)}**", snippet)

    return snippet


def list_files(dir_path: Path):
    files = []
    if dir_path.exists():
        for p in sorted(dir_path.iterdir(), key=lambda x: x.name):
            if p.is_file():
                files.append(p)
    return files


# =====================================================
# RAG CHAT CORE (safe & limited)
# =====================================================
def rag_chat(scope: str, query: str, top_k: int = 3, debug: bool = False):
    """
    scope: 'general' Î® 'invoices'
    - ÎšÎ±Î»ÎµÎ¯ Ï„Î¿ Î±Î½Ï„Î¯ÏƒÏ„Î¿Î¹Ï‡Î¿ /search endpoint.
    - Î Î±Î¯ÏÎ½ÎµÎ¹ ÎœÎ•Î§Î¡Î™ 3 chunks.
    - Î ÎµÏÎ¹Î¿ÏÎ¯Î¶ÎµÎ¹ Ï„Î¿ ÏƒÏ…Î½Î¿Î»Î¹ÎºÏŒ context ÏƒÎµ ~4000 Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚.
    - ÎšÎ¬Î½ÎµÎ¹ ÎºÎ»Î®ÏƒÎ· ÏƒÏ„Î¿ OpenAI ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· + Î»Î¯Î³Î± metadata.
    """
    endpoint = f"{API_URL}/{scope}/search"

    try:
        resp = requests.post(endpoint, json={"query": query, "top_k": top_k})
    except Exception as e:
        return {
            "answer": f"Î£Ï†Î¬Î»Î¼Î± HTTP Ï€ÏÎ¿Ï‚ backend: {e}",
            "contexts": [],
            "metadatas": [],
            "raw": None,
        }

    try:
        raw = resp.json()
    except Exception:
        return {
            "answer": f"Î¤Î¿ backend Î´ÎµÎ½ ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Î­Î³ÎºÏ…ÏÎ¿ JSON. HTTP {resp.status_code}",
            "contexts": [],
            "metadatas": [],
            "raw": None,
        }

    docs = raw.get("documents") or []
    metas = raw.get("metadatas") or []

    # Chroma: documents = [[chunk1, chunk2, ...]]
    if docs and isinstance(docs[0], list):
        contexts = docs[0]
    else:
        contexts = docs

    if metas and isinstance(metas[0], list):
        metadatas = metas[0]
    else:
        metadatas = metas

    # --- LIMIT chunks to avoid huge prompts ---
    MAX_CHUNKS = 3
    contexts = contexts[:MAX_CHUNKS]
    metadatas = metadatas[:MAX_CHUNKS]

    if not contexts:
        return {
            "answer": "Î”ÎµÎ½ Î²ÏÎ®ÎºÎ± ÏƒÏ‡ÎµÏ„Î¹ÎºÎ­Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ ÏƒÏ„Î¿ RAG. Î‘Î½Î­Î²Î±ÏƒÎµ Ï€ÏÏÏ„Î± ÎºÎ¬Ï€Î¿Î¹Î± Î±ÏÏ‡ÎµÎ¯Î±.",
            "contexts": [],
            "metadatas": [],
            "raw": raw,
        }

    # --- Build context block with char limit ---
    CONTEXT_CHAR_LIMIT = 4000
    context_block = ""
    for i, chunk in enumerate(contexts):
        meta = metadatas[i] if i < len(metadatas) else {}
        source_info = f"(source: {meta.get('filename', 'unknown')}, chunk: {meta.get('chunk', '-')})"
        piece = f"---\n{source_info}\n{chunk}\n\n"

        if len(context_block) + len(piece) > CONTEXT_CHAR_LIMIT:
            context_block += "\n...[TRUNCATED]...\n"
            break

        context_block += piece

    client = get_client()
    if client is None:
        return {
            "answer": "Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ OPENAI_API_KEY ÏƒÏ„Î¿ .env. Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎ­ Ï„Î¿ ÎºÎ±Î¹ Î¾Î±Î½Î±Ï„ÏÎ­Î¾Îµ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®.",
            "contexts": contexts,
            "metadatas": metadatas,
            "raw": raw,
        }

    system_msg = (
        "Î•Î¯ÏƒÎ±Î¹ Î²Î¿Î·Î¸ÏŒÏ‚ RAG Ï„Î¿Ï… AInteG. "
        "Î‘Ï€Î±Î½Ï„Î¬Ï‚ Î£Î¥ÎÎ¤ÎŸÎœÎ‘, ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ ÎœÎŸÎÎŸ Ï„Î¹Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… ÏƒÎ¿Ï… Î´Î¯Î½Î¿Î½Ï„Î±Î¹. "
        "Î‘Î½ Î´ÎµÎ½ Î²ÏÎ¯ÏƒÎºÎµÎ¹Ï‚ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÏƒÏ„Î¿ context, Ï€ÎµÏ‚ Î¾ÎµÎºÎ¬Î¸Î±ÏÎ± ÏŒÏ„Î¹ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î±ÏÎºÎµÏ„Î® Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±."
    )

    user_msg = (
        "Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ (context) Î³Î¹Î± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·.\n\n"
        f"{context_block}\n\n"
        f"Î•ÏÏÏ„Î·ÏƒÎ·: {query}"
    )

    try:
        chat_resp = client.chat.completions.create(
            model=os.getenv("MODEL_CHAT", "gpt-4.1-mini"),
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
            temperature=0.2,
        )
        answer = chat_resp.choices[0].message.content
    except Exception as e:
        answer = f"Î£Ï†Î¬Î»Î¼Î± LLM: {e}"

    return {
        "answer": answer,
        "contexts": contexts,
        "metadatas": metadatas,
        "raw": raw if debug else None,
    }


# =====================================================
# MODE SELECTION
# =====================================================
mode = st.radio(
    "ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î±:",
    ["General", "Invoice"],
    horizontal=True,
)

st.divider()

# ===================================================================
# ========================  GENERAL MODE  ============================
# ===================================================================
if mode == "General":
    st.subheader("ğŸ“„ General Chat + Upload + Files")
    st.write("Î‘Î½Î­Î²Î±ÏƒÎµ Î±ÏÏ‡ÎµÎ¯Î± (PDF/TXT) ÎºÎ±Î¹ ÎºÎ¬Î½Îµ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Ï€Î¬Î½Ï‰ ÏƒÏ„Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½ÏŒ Ï„Î¿Ï…Ï‚.")

    # -------------------------
    # Chat-RAG (Ï€Î¬Î½Ï‰)
    # -------------------------
    st.markdown("### ğŸ’¬ Chat-RAG (General)")

    if "general_chat" not in st.session_state:
        st.session_state.general_chat = []

    debug_general = st.checkbox("Debug mode (Î´ÎµÎ¯Î¾Îµ RAG Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±)", key="general_debug")

    # Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ
    for msg in st.session_state.general_chat:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    user_input = st.chat_input("Î¡ÏÏ„Î± ÎºÎ¬Ï„Î¹ Ï€Î¬Î½Ï‰ ÏƒÏ„Î± general Î­Î³Î³ÏÎ±Ï†Î¬ ÏƒÎ¿Ï…:")
    if user_input:
        st.session_state.general_chat.append({"role": "user", "content": user_input})

        with st.chat_message("assistant"):
            with st.spinner("Î¨Î¬Ï‡Î½Ï‰ ÏƒÏ„Î¿ RAG..."):
                result = rag_chat("general", user_input, top_k=3, debug=debug_general)
                answer = result["answer"]
                st.markdown(answer)

                contexts = result.get("contexts") or []
                metadatas = result.get("metadatas") or []

                if contexts:
                    st.markdown("### ğŸ“š Î£Ï‡ÎµÏ„Î¹ÎºÏŒ Î±Ï€ÏŒÏƒÏ€Î±ÏƒÎ¼Î±:")
                    for i, ctx in enumerate(contexts):
                        meta = metadatas[i] if i < len(metadatas) else {}
                        snippet = highlight_snippet(ctx, user_input)
                        st.markdown(
                            f"*{meta.get('filename', 'unknown')}* (chunk {meta.get('chunk', '-')})"
                        )
                        st.markdown(f"> {snippet}")
                        break  # Î´ÎµÎ¯Ï‡Î½Î¿Ï…Î¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î¿ Ï€ÏÏÏ„Î¿ snippet Î³Î¹Î± ÎºÎ±Î¸Î±ÏÏŒ UI

                if debug_general and result.get("raw") is not None:
                    st.markdown("### ğŸ”§ RAW RAG RESPONSE")
                    st.json(result["raw"])

        st.session_state.general_chat.append({"role": "assistant", "content": answer})

    st.divider()

    # -------------------------
    # Upload (ÎºÎ¬Ï„Ï‰)
    # -------------------------
    st.markdown("### ğŸ”¼ Upload (General)")
    gen_file = st.file_uploader("Î•Ï€Î¯Î»ÎµÎ¾Îµ PDF Î® TXT:", type=["pdf", "txt"], key="gen_upload")

    if gen_file is not None:
        if st.button("ğŸ“¤ Upload (General)"):
            files = {"file": (gen_file.name, gen_file.getvalue())}
            r = requests.post(f"{API_URL}/general/upload", files=files)

            st.write("Status:", r.status_code)
            try:
                st.json(r.json())
            except Exception:
                st.error("Î¤Î¿ backend Î´ÎµÎ½ ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Î­Î³ÎºÏ…ÏÎ¿ JSON.")
                st.code(r.text)

    st.divider()

    # -------------------------
    # File Manager (General)
    # -------------------------
    st.markdown("### ğŸ“ Î‘ÏÏ‡ÎµÎ¯Î± (uploads/general)")
    gen_files = list_files(GENERAL_UPLOAD_DIR)
    if not gen_files:
        st.info("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î±ÏÏ‡ÎµÎ¯Î± ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ uploads/general.")
    else:
        for p in gen_files:
            col1, col2, col3 = st.columns([4, 2, 1])
            with col1:
                st.write(p.name)
            with col2:
                size_kb = p.stat().st_size / 1024
                st.write(f"{size_kb:.1f} KB")
            with col3:
                if st.button("ğŸ—‘ï¸", key=f"del_gen_{p.name}"):
                    try:
                        p.unlink()
                        st.success(f"Î”Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎµ: {p.name}")
                        st.experimental_rerun()
                    except Exception as e:
                        st.error(f"Î£Ï†Î¬Î»Î¼Î± Î´Î¹Î±Î³ÏÎ±Ï†Î®Ï‚: {e}")

# ===================================================================
# ========================  INVOICE MODE  ============================
# ===================================================================
else:
    st.subheader("ğŸ§¾ Invoices Chat + Upload (OCR) + Files")
    st.write("Î‘Î½Î­Î²Î±ÏƒÎµ Ï„Î¹Î¼Î¿Î»ÏŒÎ³Î¹Î± (PDF/JPG/PNG) Î³Î¹Î± OCR, parsing ÎºÎ±Î¹ RAG Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·.")

    # -------------------------
    # Chat-RAG (Invoices) Î Î‘ÎÎ©
    # -------------------------
    st.markdown("### ğŸ’¬ Chat-RAG (Invoices)")

    if "invoice_chat" not in st.session_state:
        st.session_state.invoice_chat = []

    debug_invoices = st.checkbox("Debug mode (Î´ÎµÎ¯Î¾Îµ RAG Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±)", key="invoice_debug")

    for msg in st.session_state.invoice_chat:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    inv_query = st.chat_input("Î¡ÏÏ„Î± ÎºÎ¬Ï„Î¹ Ï€Î¬Î½Ï‰ ÏƒÏ„Î± invoices ÏƒÎ¿Ï…:")
    if inv_query:
        st.session_state.invoice_chat.append({"role": "user", "content": inv_query})

        with st.chat_message("assistant"):
            with st.spinner("Î¨Î¬Ï‡Î½Ï‰ ÏƒÏ„Î± invoices..."):
                result = rag_chat("invoices", inv_query, top_k=3, debug=debug_invoices)
                answer = result["answer"]
                st.markdown(answer)

                contexts = result.get("contexts") or []
                metadatas = result.get("metadatas") or []

                if contexts:
                    st.markdown("### ğŸ“š Î£Ï‡ÎµÏ„Î¹ÎºÏŒ Î±Ï€ÏŒÏƒÏ€Î±ÏƒÎ¼Î± Î±Ï€ÏŒ invoice:")
                    for i, ctx in enumerate(contexts):
                        meta = metadatas[i] if i < len(metadatas) else {}
                        snippet = highlight_snippet(ctx, inv_query)
                        st.markdown(
                            f"*{meta.get('filename', 'unknown')}* (chunk {meta.get('chunk', '-')})"
                        )
                        st.markdown(f"> {snippet}")
                        break

                if debug_invoices and result.get("raw") is not None:
                    st.markdown("### ğŸ”§ RAW RAG RESPONSE (Invoices)")
                    st.json(result["raw"])

        st.session_state.invoice_chat.append({"role": "assistant", "content": answer})

    st.divider()

    # -------------------------
    # Upload + OCR (ÎºÎ¬Ï„Ï‰)
    # -------------------------
    st.markdown("### ğŸ”¼ Upload Invoice (OCR)")
    inv_file = st.file_uploader(
        "Î•Ï€Î¯Î»ÎµÎ¾Îµ invoice (PDF/JPG/PNG):",
        type=["pdf", "jpg", "jpeg", "png"],
        key="inv_upload"
    )

    if inv_file is not None:
        if st.button("ğŸ“¤ Upload & OCR"):
            files = {"file": (inv_file.name, inv_file.getvalue())}
            r = requests.post(f"{API_URL}/invoices/upload", files=files)

            st.write("Status:", r.status_code)
            try:
                data = r.json()
            except Exception:
                st.error("Î¤Î¿ backend Î´ÎµÎ½ ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Î­Î³ÎºÏ…ÏÎ¿ JSON.")
                st.code(r.text)
            else:
                st.success("OCR & parsing Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎ±Î½!")

                st.markdown("### ğŸ“ OCR Preview (Ï‰Ï‚ text)")
                st.code(data.get("ocr_preview", ""))

                st.markdown("### ğŸ“¦ Parsed Invoice JSON")
                st.json(data.get("parsed_invoice", {}))

                if "price_changes" in data:
                    st.markdown("### ğŸ” Î Î¹Î¸Î±Î½Î­Ï‚ Î±Î»Î»Î±Î³Î­Ï‚ Ï„Î¹Î¼ÏÎ½")
                    pcs = data.get("price_changes", [])
                    if pcs:
                        for pc in pcs:
                            st.warning(
                                f"**{pc['product']}**\n\n"
                                f"Old price: {pc['old_price']}\n"
                                f"New price: {pc['new_price']}"
                            )
                    else:
                        st.info("Î”ÎµÎ½ ÎµÎ½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎ±Î½ Î±Î»Î»Î±Î³Î­Ï‚ Ï„Î¹Î¼ÏÎ½.")

                if "mlg_candidates" in data:
                    st.markdown("### ğŸ·ï¸ MLG Candidates")
                    mlg = data.get("mlg_candidates", [])
                    if mlg:
                        st.json(mlg)
                    else:
                        st.info("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ MLG items.")

    st.divider()

    # -------------------------
    # File Manager (Invoices)
    # -------------------------
    st.markdown("### ğŸ“ Î‘ÏÏ‡ÎµÎ¯Î± (uploads/invoices)")
    inv_files = list_files(INVOICE_UPLOAD_DIR)
    if not inv_files:
        st.info("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î±ÏÏ‡ÎµÎ¯Î± ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ uploads/invoices.")
    else:
        for p in inv_files:
            col1, col2, col3 = st.columns([4, 2, 1])
            with col1:
                st.write(p.name)
            with col2:
                size_kb = p.stat().st_size / 1024
                st.write(f"{size_kb:.1f} KB")
            with col3:
                if st.button("ğŸ—‘ï¸", key=f"del_inv_{p.name}"):
                    try:
                        p.unlink()
                        st.success(f"Î”Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎµ: {p.name}")
                        st.experimental_rerun()
                    except Exception as e:
                        st.error(f"Î£Ï†Î¬Î»Î¼Î± Î´Î¹Î±Î³ÏÎ±Ï†Î®Ï‚: {e}")
